{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection and recognition training pipeline\n",
    "\n",
    "The following example illustrates how to fine-tune an InceptionResnetV1 model on your own dataset. This will mostly follow standard pytorch training patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define run parameters\n",
    "\n",
    "The dataset should follow the VGGFace2/ImageNet-style directory layout. Modify `data_dir` to the location of the dataset on wish to finetune on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '../base_and_generated'\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 8\n",
    "workers = 0 if os.name == 'nt' else 4 # 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "\n",
    "See `help(MTCNN)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtcnn = MTCNN(\n",
    "#     image_size=160, margin=0, min_face_size=20,\n",
    "#     thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "#     device=device\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfom MTCNN facial detection\n",
    "\n",
    "Iterate through the DataLoader object and obtain cropped faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "# dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "# dataset.idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset.samples = [\n",
    "#     (p, p.replace(data_dir, data_dir + '_cropped'))\n",
    "#         for p, _ in dataset.samples\n",
    "# ]\n",
    "\n",
    "# # loader = DataLoader(\n",
    "# #     dataset,\n",
    "# #     num_workers=workers,\n",
    "# #     batch_size=batch_size,\n",
    "# #     collate_fn=training.collate_pil\n",
    "# # )\n",
    "# loader = DataLoader(dataset, collate_fn=training.collate_pil, num_workers=workers)\n",
    "\n",
    "# # x: image object\n",
    "# # y: save path of corresponding object\n",
    "# for i, (x, y) in enumerate(loader):\n",
    "#     mtcnn(x, save_path=y)\n",
    "#     print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    \n",
    "# # Remove mtcnn to reduce GPU memory usage\n",
    "# del mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inception Resnet V1 module\n",
    "\n",
    "See `help(InceptionResnetV1)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.cuda.empty_cache()\n",
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained='casia-webface',\n",
    "    num_classes=2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define optimizer, scheduler, dataset, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.001\n",
    "params = [\n",
    "    {'params': [param for name, param in resnet.named_parameters() if name in ['logits.weight', 'logits.bias']], 'lr': base_lr},\n",
    "    {'params': [param for name, param in resnet.named_parameters() if name not in ['logits.weight', 'logits.bias']], 'lr': base_lr * 0.01}\n",
    "]\n",
    "optimizer = optim.Adam(params)\n",
    "scheduler = MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "# add random rotation and flip to data augmentation\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomRotation(degrees=(-10, 10)),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(10),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "train_data_dir = '../data/base_and_final_cropped'\n",
    "val_data_dir = '../data/test_images_cropped'\n",
    "train_dataset = datasets.ImageFolder(train_data_dir, transform=trans)\n",
    "val_dataset = datasets.ImageFolder(val_data_dir, transform=trans)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# # freeze all layers except the final classification layer\n",
    "# for name, param in resnet.named_parameters():\n",
    "#     if name not in ['logits.weight', 'logits.bias']:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "\n",
    "from torchmetrics.functional.classification import binary_f1_score\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy,\n",
    "    #'tl_acc': Accuracy(task='binary').to(device),\n",
    "    'fscore': BinaryF1Score().to(device)# F1Score(task=\"multiclass\", average=None, num_classes=2).to(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial\n",
      "----------\n",
      "\n",
      "Epoch 1/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train |     2/2    | loss:    0.4792 | fps:  144.9581 | acc:    0.8032 | fscore:    0.8231   \n",
      "Valid |    23/23   | loss:    0.4545 | fps: 1442.7217 | acc:    0.8367 | fscore:    0.6744   \n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.2392 | fps:  150.9082 | acc:    0.9688 | fscore:    0.9722   \n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.1194 | fps:  151.2059 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.3128 | fps: 1446.2366 | acc:    0.8906 | fscore:    0.7642   \n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0583 | fps:  152.6493 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 5/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0445 | fps:  150.2276 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2216 | fps: 1460.9882 | acc:    0.9305 | fscore:    0.8246   \n",
      "\n",
      "Epoch 6/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0248 | fps:  152.9141 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 7/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0253 | fps:  149.6134 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2170 | fps: 1444.1940 | acc:    0.9350 | fscore:    0.8417   \n",
      "\n",
      "Epoch 8/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0203 | fps:  152.9908 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 9/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0190 | fps:  152.9048 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2084 | fps: 1403.3708 | acc:    0.9393 | fscore:    0.8373   \n",
      "\n",
      "Epoch 10/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0181 | fps:  150.5379 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 11/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0233 | fps:  150.2955 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.1989 | fps: 1462.2974 | acc:    0.9450 | fscore:    0.8441   \n",
      "\n",
      "Epoch 12/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0191 | fps:  150.2870 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 13/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0285 | fps:  150.3101 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2046 | fps: 1452.4667 | acc:    0.9393 | fscore:    0.8290   \n",
      "\n",
      "Epoch 14/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0162 | fps:  151.9189 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 15/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0173 | fps:  149.3731 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2034 | fps: 1431.1165 | acc:    0.9364 | fscore:    0.8107   \n",
      "\n",
      "Epoch 16/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0252 | fps:  152.1225 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 17/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0278 | fps:  151.2855 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2027 | fps: 1432.7716 | acc:    0.9361 | fscore:    0.8173   \n",
      "\n",
      "Epoch 18/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0192 | fps:  152.9124 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 19/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0351 | fps:  151.2935 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.1999 | fps: 1461.5320 | acc:    0.9409 | fscore:    0.8126   \n",
      "\n",
      "Epoch 20/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0209 | fps:  151.7034 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 21/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0179 | fps:  151.0148 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2038 | fps: 1469.6987 | acc:    0.9404 | fscore:    0.8258   \n",
      "\n",
      "Epoch 22/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0217 | fps:  152.2451 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 23/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0204 | fps:  151.3400 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2035 | fps: 1462.9458 | acc:    0.9461 | fscore:    0.8472   \n",
      "\n",
      "Epoch 24/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0548 | fps:  149.9945 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 25/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0876 | fps:  152.0662 | acc:    0.9762 | fscore:    0.9839   \n",
      "Valid |    23/23   | loss:    0.2012 | fps: 1448.4740 | acc:    0.9472 | fscore:    0.8474   \n",
      "\n",
      "Epoch 26/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0160 | fps:  150.6486 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 27/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0209 | fps:  151.9655 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2014 | fps: 1464.1632 | acc:    0.9427 | fscore:    0.8249   \n",
      "\n",
      "Epoch 28/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0174 | fps:  152.7797 | acc:    1.0000 | fscore:    1.0000   \n",
      "\n",
      "Epoch 29/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0175 | fps:  150.2420 | acc:    1.0000 | fscore:    1.0000   \n",
      "Valid |    23/23   | loss:    0.2043 | fps: 1462.9823 | acc:    0.9432 | fscore:    0.8325   \n",
      "\n",
      "Epoch 30/30\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0215 | fps:  151.5655 | acc:    1.0000 | fscore:    1.0000   \n"
     ]
    }
   ],
   "source": [
    "# writer = SummaryWriter()\n",
    "# writer.iteration, writer.interval = 0, 1\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "# resnet.eval()\n",
    "# training.pass_epoch(\n",
    "#     resnet, loss_fn, val_loader,\n",
    "#     batch_metrics=metrics, show_running=True, device=device,\n",
    "#     writer=writer\n",
    "# )\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=None\n",
    "    )\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        resnet.eval()\n",
    "        training.pass_epoch(\n",
    "            resnet, loss_fn, val_loader,\n",
    "            batch_metrics=metrics, show_running=True, device=device,\n",
    "            writer=None\n",
    "        )\n",
    "    #writer.iteration += 1  # Increment writer.iteration after each epoch\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import csv\n",
    "\n",
    "# # Read data from the CSV file\n",
    "# epochs = []\n",
    "# accuracies = []\n",
    "\n",
    "# with open('results.csv', 'r') as file:\n",
    "#     csv_reader = csv.DictReader(file)\n",
    "#     for row in csv_reader:\n",
    "#         epochs.append(int(row['epoch']))\n",
    "#         accuracies.append(float(row['accuracy']))\n",
    "\n",
    "# # Create the plot\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(epochs, accuracies, marker='o')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy vs. Epoch for the model trained on generated images')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
